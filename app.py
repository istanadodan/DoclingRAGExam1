import asyncio
import streamlit as st
import datetime
import json
import orjson
import warnings
from tools.async_tools import run_async


def setup() -> None:
    from transformers import logging as logging_logger
    import logging

    # Milvus ë¡œê±°ë§Œ ëŒ€ìƒìœ¼ë¡œ ì„¤ì • (íŒ¨í‚¤ì§€ ì´ë¦„ í™•ì¸ í•„ìš”)
    milvus_logger = logging.getLogger(
        "milvus"
    )  # ë˜ëŠ” "pymilvus", "async_milvus_client"
    milvus_logger.setLevel(logging.INFO)

    logging_logger.set_verbosity_error()


def get_event_loop_safe():
    try:
        return asyncio.get_running_loop()
    except RuntimeError:
        # Streamlitì²˜ëŸ¼ ì‹¤í–‰ ì¤‘ ë£¨í”„ê°€ ì—†ì„ ë•ŒëŠ” ê¸°ë³¸ ë£¨í”„ ê°€ì ¸ì˜¤ê¸°
        return asyncio.get_event_loop()


def main():
    """_ë©”ì¸í•¨ìˆ˜_

    Returns:
        _type_: _description_
    """
    if not "env_loaded" in st.session_state:
        from dotenv import load_dotenv

        load_dotenv()
        # setup()

    st.session_state.env_loaded = True
    # ScriptRunContext ê²½ê³  ë¬´ì‹œ
    warnings.filterwarnings("ignore", message=".*ScriptRunContext.*")
    warnings.filterwarnings("ignore", category=UserWarning)

    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(page_title="AI ì±„íŒ… ì–´ì‹œìŠ¤í„´íŠ¸", page_icon="ğŸ’¬", layout="wide")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if "uploaded_files" not in st.session_state:
        st.session_state.uploaded_files = []

    # ë©”ì¸ ì œëª©
    st.title("ğŸ’¬ AI ì±„íŒ… ì–´ì‹œìŠ¤í„´íŠ¸")

    # ì‚¬ì´ë“œë°” - ì˜µì…˜ ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # ëŒ€í™” ì´ë ¥ ê°œìˆ˜ ì„¤ì •
        max_history = st.slider(
            "ëŒ€í™” ì´ë ¥ í‘œì‹œ ê°œìˆ˜",
            min_value=5,
            max_value=50,
            value=20,
            step=5,
            help="ìµœê·¼ ëª‡ ê°œì˜ ëŒ€í™”ê¹Œì§€ í‘œì‹œí• ì§€ ì„¤ì •í•©ë‹ˆë‹¤.",
        )

        st.divider()

        # ëª¨ë¸ ì˜µì…˜ ì„ íƒ
        st.subheader("ğŸ¤– ëª¨ë¸ ì„¤ì •")
        model_option = st.selectbox(
            "AI ëª¨ë¸ ì„ íƒ",
            ["GPT-4", "GPT-3.5-turbo", "Claude-3", "Gemini-Pro"],
            index=0,
        )

        temperature = st.slider(
            "ì°½ì˜ì„± ìˆ˜ì¤€ (Temperature)",
            min_value=0.0,
            max_value=2.0,
            value=0.7,
            step=0.1,
            help="ë†’ì„ìˆ˜ë¡ ë” ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
        )

        max_tokens = st.number_input(
            "ìµœëŒ€ í† í° ìˆ˜", min_value=100, max_value=4000, value=2000, step=100
        )

        st.divider()

        # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=["txt", "pdf", "docx", "csv", "json", "py", "md"],
            accept_multiple_files=True,
            help="í…ìŠ¤íŠ¸, PDF, Word, CSV, JSON, Python, Markdown íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        )

        if uploaded_file:
            for file in uploaded_file:
                if file not in st.session_state.uploaded_files:
                    st.session_state.uploaded_files.append(
                        {
                            "name": file.name,
                            "size": file.size,
                            "type": file.type,
                            "upload_time": datetime.datetime.now().strftime(
                                "%Y-%m-%d %H:%M:%S"
                            ),
                        }
                    )

            st.success(f"{len(uploaded_file)}ê°œ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

            # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            if st.session_state.uploaded_files:
                st.write("**ì—…ë¡œë“œëœ íŒŒì¼ë“¤:**")
                for i, file_info in enumerate(st.session_state.uploaded_files):
                    with st.expander(f"ğŸ“„ {file_info['name']}"):
                        st.write(f"í¬ê¸°: {file_info['size']:,} bytes")
                        st.write(f"íƒ€ì…: {file_info['type']}")
                        st.write(f"ì—…ë¡œë“œ ì‹œê°„: {file_info['upload_time']}")
                        if st.button(f"ì‚­ì œ", key=f"delete_{i}"):
                            st.session_state.uploaded_files.pop(i)
                            st.rerun()

        st.divider()

        # ëŒ€í™” ë‚´ì—­ ê´€ë¦¬
        st.subheader("ğŸ“‹ ëŒ€í™” ê´€ë¦¬")
        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", use_container_width=True):
                st.session_state.chat_history = []
                st.rerun()

        with col2:
            if st.button("ğŸ’¾ ëŒ€í™” ì €ì¥", use_container_width=True):
                if st.session_state.chat_history:
                    chat_data = {
                        "timestamp": datetime.datetime.now().isoformat(),
                        "model": model_option,
                        "settings": {
                            "temperature": temperature,
                            "max_tokens": max_tokens,
                        },
                        "conversation": st.session_state.chat_history,
                    }
                    st.download_button(
                        label="ğŸ“¥ JSON ë‹¤ìš´ë¡œë“œ",
                        # data=json.dumps(chat_data, ensure_ascii=False, indent=2),
                        data=orjson.dumps(chat_data),
                        file_name=f"chat_history_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                    )

    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    col1, col2 = st.columns([3, 1])

    with col1:
        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ ì˜ì—­
        st.subheader("ğŸ’­ ëŒ€í™”ì°½")

        chat_container = st.container()

        with chat_container:
            # ìµœê·¼ ëŒ€í™” ì´ë ¥ë§Œ í‘œì‹œ
            display_history = (
                st.session_state.chat_history[-max_history:]
                if len(st.session_state.chat_history) > max_history
                else st.session_state.chat_history
            )

            if not display_history:
                st.info("ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
            else:
                for i, chat in enumerate(display_history):
                    timestamp = chat.get("timestamp", "")

                    # ì‚¬ìš©ì ë©”ì‹œì§€
                    with st.chat_message("user"):
                        st.write(f"**[{timestamp}]**")
                        st.write(chat["user"])

                    # AI ì‘ë‹µ
                    with st.chat_message("assistant"):
                        st.write(f"**[{timestamp}] {model_option}**")
                        st.write(chat["assistant"])

        # ì§ˆì˜ ì…ë ¥ì°½
        st.subheader("âœï¸ ì§ˆë¬¸ ì…ë ¥")

        with st.form("chat_form", clear_on_submit=True):
            user_input = st.text_area(
                "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                height=100,
                placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                help="Ctrl+Enterë¡œ ë¹ ë¥´ê²Œ ì „ì†¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            )

            col_submit1, col_submit2, col_submit3 = st.columns([1, 1, 2])

            with col_submit1:
                submitted = st.form_submit_button("ğŸš€ ì „ì†¡", use_container_width=True)

            with col_submit2:
                clear_input = st.form_submit_button(
                    "ğŸ§¹ ì§€ìš°ê¸°", use_container_width=True
                )

            with col_submit3:
                include_files = st.checkbox(
                    "ì—…ë¡œë“œëœ íŒŒì¼ í¬í•¨", help="ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ë¥¼ í•¨ê»˜ ì „ì†¡í•©ë‹ˆë‹¤."
                )

    with col2:
        # í†µê³„ ë° ì •ë³´ í‘œì‹œ
        st.subheader("ğŸ“Š ëŒ€í™” í†µê³„")

        total_chats = len(st.session_state.chat_history)

        # ë©”íŠ¸ë¦­ í‘œì‹œ
        st.metric("ì´ ëŒ€í™” ìˆ˜", total_chats)
        st.metric("ì—…ë¡œë“œëœ íŒŒì¼", len(st.session_state.uploaded_files))
        st.metric("í˜„ì¬ ëª¨ë¸", model_option)

        # ìµœê·¼ ëŒ€í™” ì‹œê°„
        if st.session_state.chat_history:
            last_chat_time = st.session_state.chat_history[-1].get(
                "timestamp", "Unknown"
            )
            st.info(f"**ë§ˆì§€ë§‰ ëŒ€í™”:** {last_chat_time}")

        # ì„¤ì • ìš”ì•½
        with st.expander("ğŸ”§ í˜„ì¬ ì„¤ì •"):
            st.write(f"**ëª¨ë¸:** {model_option}")
            st.write(f"**ì°½ì˜ì„±:** {temperature}")
            st.write(f"**ìµœëŒ€ í† í°:** {max_tokens}")
            st.write(f"**í‘œì‹œ ì´ë ¥:** {max_history}ê°œ")

    # í¼ ì œì¶œ ì²˜ë¦¬
    if submitted and user_input.strip():
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # íŒŒì¼ ì •ë³´ í¬í•¨ ì—¬ë¶€ í™•ì¸
        file_context = ""
        if include_files and st.session_state.uploaded_files:
            file_context = "\n\n[ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´]\n"
            for file_info in st.session_state.uploaded_files:
                file_context += f"- {file_info['name']} ({file_info['type']}, {file_info['size']:,} bytes)\n"

        # ì‹¤ì œ AI ëª¨ë¸ ëŒ€ì‹  ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„± (ë°ëª¨ìš©)
        def generate_response(user_query: str, model: str, temp: float) -> str:
            responses = [
                f"ì•ˆë…•í•˜ì„¸ìš”! {model} ëª¨ë¸ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤. ì§ˆë¬¸: '{user_query[:50]}...' ì— ëŒ€í•´ ìƒê°í•´ë³´ê³  ìˆìŠµë‹ˆë‹¤.",
                f"í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì´ë„¤ìš”! {model}ì´ ì°½ì˜ì„± ìˆ˜ì¤€ {temp}ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                f"ì§ˆë¬¸ì„ ì˜ ì´í•´í–ˆìŠµë‹ˆë‹¤. {model} ëª¨ë¸ì˜ ìµœëŒ€ {max_tokens} í† í°ìœ¼ë¡œ ë‹µë³€í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                f"ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤! {model}ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                f"ë„¤, ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. {model} ëª¨ë¸ë¡œ ìµœì„ ì˜ ë‹µë³€ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.",
            ]
            import random

            return (
                random.choice(responses)
                + f"\n\nì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—¬ê¸°ì— {model} API í˜¸ì¶œ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤."
                + file_context
            )

        # AI ì‘ë‹µ ìƒì„±
        from model.query import query

        try:
            ai_response = run_async(query(user_input))
        except RuntimeError:
            ai_response = "ERROR"

        # ai_response = generate_response(
        #     user_input + file_context, model_option, temperature
        # )

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        chat_entry = {
            "timestamp": timestamp,
            "user": user_input,
            "assistant": ai_response,
            "model": model_option,
            "settings": {"temperature": temperature, "max_tokens": max_tokens},
        }

        st.session_state.chat_history.append(chat_entry)

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()
    elif clear_input:
        st.rerun()

    # í•˜ë‹¨ ì •ë³´
    st.divider()
    st.caption(
        "ğŸ’¡ **ì‚¬ìš© íŒ:** ì‚¬ì´ë“œë°”ì—ì„œ AI ëª¨ë¸ê³¼ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )

    # í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ ì•ˆë‚´
    with st.expander("âŒ¨ï¸ í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤"):
        st.write(
            """
        - **Ctrl + Enter**: ë©”ì‹œì§€ ì „ì†¡
        - **Tab**: ë‹¤ìŒ ì…ë ¥ì°½ìœ¼ë¡œ ì´ë™
        - **Shift + Tab**: ì´ì „ ì…ë ¥ì°½ìœ¼ë¡œ ì´ë™
        """
        )


if __name__ == "__main__":
    main()
